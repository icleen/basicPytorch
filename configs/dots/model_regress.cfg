
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

# Downsample

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3


[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3

######################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=20
activation=leaky

[flatten]
dims=-1, 3380

[linear]
input=3380
output=2048
activation=relu

[linear]
input=2048
output=338
activation=sigmoid

[regressor]
loss=mse


[route]
layers = -6

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 61



[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=5
activation=leaky

[flatten]
dims=-1, 3380

[linear]
input=3380
output=2048
activation=relu

[linear]
input=2048
output=338
activation=sigmoid

[regressor]
loss=mse



[route]
layers = -6

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 36



[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=0
filters=2
activation=leaky

[flatten]
dims=-1, 5408

[linear]
input=5408
output=2048
activation=relu

[linear]
input=2048
output=338
activation=sigmoid

[regressor]
loss=mse
